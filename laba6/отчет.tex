\documentclass [12pt]{article}


\usepackage{ucs}
\usepackage[utf8x]{inputenc} %Поддержка UTF8
\usepackage{cmap} % Улучшенный поиск русских слов в полученном pdf-файле
\usepackage[english,russian]{babel} %Пакет для поддержки русского и английского языка
\usepackage{graphicx} %Поддержка графиков
\usepackage{float} %Поддержка float-графиков
\usepackage[left=20mm,right=15mm, top=20mm,bottom=20mm,bindingoffset=0cm]{geometry}
\usepackage{mathtools} 
\usepackage{amsmath}
\usepackage{setspace,amsmath}
\usepackage{amsmath,amssymb}
\usepackage{dsfont}
\renewcommand{\baselinestretch}{1.2}
 
\usepackage{color} 
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

\usepackage{listings}
 
\lstset{
	language=Python,
	basicstyle=\ttm,
	otherkeywords={self},             % Add keywords here
	keywordstyle=\ttb\color{deepblue},
	emph={MyClass,__init__},          % Custom highlighting
	emphstyle=\ttb\color{deepred},    % Custom highlighting style
	stringstyle=\color{deepgreen},
	frame=tb,                         % Any extra options here
	showstringspaces=false            % 
}
 
\usepackage{hyperref}
 
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
    unicode=false,          % non-Latin characters in Acrobat’s bookmarks
    pdftoolbar=true,        % show Acrobat’s toolbar?
    pdfmenubar=true,        % show Acrobat’s menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={My title},    % title
    pdfauthor={Author},     % author
    pdfsubject={Subject},   % subject of the document
    pdfcreator={Creator},   % creator of the document
    pdfproducer={Producer}, % producer of the document
    pdfkeywords={keyword1} {key2} {key3}, % list of keywords
    pdfnewwindow=true,      % links in new PDF window
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=black,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\title{}
\date{}
\author{}

\begin{document}
\begin{titlepage}
\thispagestyle{empty}
\begin{center}
Федеральное государственное бюджетное образовательное учреждение высшего профессионального образования \\Московский государственный технический университет имени Н.Э. Баумана

\end{center}
\vfill
\centerline{\large{Лабораторная работа №6}}
\centerline{\large{по курсу <<Численные методы>>}}
\centerline{\large{<<Метод наискорейшего спуска поиска минимума функций многих переменных>>}}
\vfill
\hfill\parbox{5cm} {
           Выполнил:\\
           студент группы ИУ9-62Б \hfill \\
           Головкин Дмитрий\hfill \medskip\\
           Проверила:\\
           Домрачева А.Б.\hfill
       }
\centerline{Москва, 2023}
\clearpage
\end{titlepage}

\textsc{\textbf{Цель:}} 

Анализ метода наискорейшего спуска поиска минимума функций многих переменных.

\textsc{\textbf{Постановка задачи:}} 

\textbf{Дано:}  Функция нескольких переменных $ f(x_{1}, x_{2}, ...,x_{n}) $ и некоторое начальное приближение $ X^{0} = (x_{1}^{0}, ..., x_{n}^{0}). $

\textbf{Найти:} Минимум функции нескольких переменных с заданной точностью.

\textbf{Тестовый пример:} 

В качестве тестового примера были предложены следующие входные данные: $$ f(X) = e^{x_{1}} + (x_{1} + x_{2})^{2}, \quad X^{0} = (1,1) .$$

\textbf{Описание методов:}

Пусть мы имеем некоторое приближение к минимуму $X^{k} = (x_{1}^{k},...,x_{n}^{k})$. Рассмотрим функцию одной переменной $$ \phi_{k}(t) = f(x_{1}^k - t\frac{\partial f}{\partial x_{1}}(X^{k}),...,x_{n}^k - t\frac{\partial f}{\partial x_{n}}(X^{k})) = f(X^{k} - tgradf(X^{k})), $$ где вектор $ gradf(X^{k}) = (\frac{\partial f}{\partial x_{1}}(X^{k}),...,\frac{\partial f}{\partial x_{n}}(X^{k}) ) $ - градиент  функции f в точке $ X^{k}$. 

Обозначим точку минимума функции $\phi_{k}(t)$ через $t^{*}$. Тогда имеем следующую форму $$ X^{k+1} = X^{k} - t^{*}gradf(X^{k}) .$$
Процесс поиска минимума продолжаем до тех пор, пока $||gradf(X^{k})|| = \max_{1 \leq i \leq n} |\frac{\partial f}{\partial x_{i}}(X^{k})|$ не станет меньше допустимой погрешности $\epsilon$.

В большинстве случаев точно искать минимум функции $\phi_{k}(t)$ не нужно и достаточно ограничиться лишь одним приближением. Тогда особенно простым будет вид итерации в двумерном случае $$ (x_{k+1}, y_{k+1}) = (x_{k} - t^{k}\frac{\partial f}{\partial x} , y_{k} - t^{k}\frac{\partial f}{\partial y}) ,$$ где $t^{k} = \frac{\phi_{k}'(0)}{\phi_{k}''(0)}, \quad \phi_{k}'(0) = -(\frac{\partial f}{\partial x})^{2} - (\frac{\partial f}{\partial y})^{2}, \quad \phi_{k}''(0) = \frac{\partial f^{2}}{\partial x^{2}}(\frac{\partial f}{\partial x})^{2} + 2\frac{\partial f^{2}}{\partial x \partial y}\frac{\partial f}{\partial x}\frac{\partial f}{\partial y} + \frac{\partial f^{2}}{\partial y^{2}}(\frac{\partial f}{\partial y})^{2}$, все производные беруться в точке $(x_{k}, y_{k})$.

\textsc{\textbf{Практическая реализация:}}
Листинг 1. Метод наискорейшего спуска поиска минимума функций двух переменных
\begin{lstlisting}[language=python]
#!python
# -*- coding: utf-8 -*-
import numpy as np

alpha = 0.1 * 4
beta = 0.1 * 4
A = np.array([[10 + alpha, -1, 0.2, 2],
              [1, 12 - alpha, -2, 0.1],
              [0.3, -4, 12 - alpha, 1],
              [0.2, -0.3, -0.5, 8 - alpha]
              ])
b = np.array([1 + beta, 2 - beta, 3, 1])
# A = np.ones((4,4)) - A
# alpha = 0.01 * 4
# beta = 0.01 * 4
# A = np.array([[2 + alpha, 1, -0.1, 1],
#               [0.4, 0.5 - alpha, 4, -8.5],
#               [0.3, -1, 1 + 2*alpha, 5.2],
#               [1, 0.2, 2.5, -1 + alpha]
#               ])
# b = np.array([2.7 - beta, 21.9, -3.9, 9.9])

F = []
for i in range(len(A)):
    buf = A[i]
    buf = buf * -1
    buf = buf / (A[i][i] * -1)
    buf[i] = 0
    F.append(buf)
F = np.asarray(F)
F

c = []
for i in range(len(b)):
    buf = b[i] / A[i][i]
    c.append(buf)
c = np.asarray(c)
c

F_norm = max([x.sum() for x in np.array([[abs(x) for x in elem] for elem in F])])
F_norm

def calculate_abs_error(x_k, x_k_min_1):
    m = x_k - x_k_min_1
    norm = max([x.sum() for x in np.array([abs(elem) for elem in m])])
    return (F_norm * norm) / (1 - F_norm)

def calculate_rel_error(abs_err, x_k):
    return abs_err / max([x.sum() for x in np.array([abs(elem) for elem in x_k])])

x_begin = c 
rel_err = 1
k = 1
while rel_err > 0.01:
    x_new = F @ x_begin + c
    abs_err = calculate_abs_error(x_new, x_begin)
    print('--------------------')
    print('Abs error for', k, 'iter - ', abs_err)
    rel_err = calculate_rel_error(abs_err, x_new)
    print('Rel error for', k, 'iter - ', rel_err)
    k += 1
    x_begin = x_new

F_d = np.tril(F)
F_u = np.triu(F)

x_begin = c 
rel_err = 1
k = 1
while rel_err > 1e-4:
    x_new = F_u @ x_begin
    x_new = F_d @ x_new + c
    abs_err = calculate_abs_error(x_new, x_begin)
    print('--------------------')
    print('Abs error for', k, 'iter - ', abs_err)
    rel_err = calculate_rel_error(abs_err, x_new)
    print('Rel error for', k, 'iter - ', rel_err)
    k += 1
    x_begin = x_new

\end{lstlisting}

\textbf{Результаты:}

В результате работы программы были получены следующие результаты: 
\[
    F_{4\times 4} = 
    \begin{pmatrix}
      0. & -0.09615385 & 0.01923077 & 0.19230769\\
      0.0862069 & 0. & -0.17241379 & 0.00862069\\
      0.02586207 & -0.34482759 & 0. & 0.0862069\\
      0.02631579 & -0.03947368 & -0.06578947 & 0.
    \end{pmatrix}
\]
\[
  c_{1\times 4} = 
  \begin{pmatrix}
    0.13461538 \\
    0.13793103 \\
    0.25862069 \\
    0.13157895 
  \end{pmatrix}
\]
$ ||F|| = 0.45689655172413796$.

Результат выполнение программы (Листинг 1), метод простой итерации, относительная погрешность 0.01:
\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Номер итерации $k$ & Абсолютная погрешность $\Delta_{k}$ & Относительная погрешность $\delta_{k}$ \\ \hline
1 & 0.02754147575866707 & 0.12192821609126081  \\ \hline
2 & 0.008237953160882702 & 0.03495471902485724  \\ \hline
3 & 0.0017619754007710238 & 0.0075433303607050734  \\ \hline
\end{tabular}
\end{center}
\end{table} 
Метод с заданными параметрами сошелся за 3 итерации.

Результат выполнение программы (Листинг 1), метод Зейделя, относительная погрешность $10^-4$:
\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Номер итерации $k$ & Абсолютная погрешность $\Delta_{k}$ & Относительная погрешность $\delta_{k}$ \\ \hline
1 & 0.01297631511809442 & 0.04735097440978927  \\ \hline
2 & 0.0007772513942147164 & 0.0028266845885775767  \\ \hline
3 & 4.670064163651293e-05 & 0.00016980521355419676  \\ \hline
4 & 2.8044621287576496e-06 & 1.0197001622219773e-05  \\ \hline
\end{tabular}
\end{center}
\end{table}
Метод с заданными параметрами сошелся за 4 итерации.

\textbf{Выводы:}

В ходе выполнения лабораторной работы был рассмотрен метод простой итерации и метод Зейделя для решения СЛАУ. Для этих методов была написана реализация на языке программирования Python. Анализируя результаты полученной программы, можно заметить, что метод Зейделя сходится быстрее, чем метод простой итерации. Оба метода требуют преобразования СЛАУ к определенному виду, а также наличие нормы матрицы, которая будет меньше единицы. Последнее условие может не всегда выполняться, поэтому может потребоваться приведение СЛАУ к виду, обеспечивающему сходимость методов. 
\end{document}
