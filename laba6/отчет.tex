\documentclass [12pt]{article}


\usepackage{ucs}
\usepackage[utf8x]{inputenc} %Поддержка UTF8
\usepackage{cmap} % Улучшенный поиск русских слов в полученном pdf-файле
\usepackage[english,russian]{babel} %Пакет для поддержки русского и английского языка
\usepackage{graphicx} %Поддержка графиков
\usepackage{float} %Поддержка float-графиков
\usepackage[left=20mm,right=15mm, top=20mm,bottom=20mm,bindingoffset=0cm]{geometry}
\usepackage{mathtools} 
\usepackage{amsmath}
\usepackage{setspace,amsmath}
\usepackage{amsmath,amssymb}
\usepackage{dsfont}
\renewcommand{\baselinestretch}{1.2}
 
\usepackage{color} 
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

\usepackage{listings}
 
\lstset{
	language=Python,
	basicstyle=\ttm,
	otherkeywords={self},             % Add keywords here
	keywordstyle=\ttb\color{deepblue},
	emph={MyClass,__init__},          % Custom highlighting
	emphstyle=\ttb\color{deepred},    % Custom highlighting style
	stringstyle=\color{deepgreen},
	frame=tb,                         % Any extra options here
	showstringspaces=false            % 
}
 
\usepackage{hyperref}
 
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
    unicode=false,          % non-Latin characters in Acrobat’s bookmarks
    pdftoolbar=true,        % show Acrobat’s toolbar?
    pdfmenubar=true,        % show Acrobat’s menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={My title},    % title
    pdfauthor={Author},     % author
    pdfsubject={Subject},   % subject of the document
    pdfcreator={Creator},   % creator of the document
    pdfproducer={Producer}, % producer of the document
    pdfkeywords={keyword1} {key2} {key3}, % list of keywords
    pdfnewwindow=true,      % links in new PDF window
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=black,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\title{}
\date{}
\author{}

\begin{document}
\begin{titlepage}
\thispagestyle{empty}
\begin{center}
Федеральное государственное бюджетное образовательное учреждение высшего профессионального образования \\Московский государственный технический университет имени Н.Э. Баумана

\end{center}
\vfill
\centerline{\large{Лабораторная работа №6}}
\centerline{\large{по курсу <<Численные методы>>}}
\centerline{\large{<<Метод наискорейшего спуска поиска минимума функций многих переменных>>}}
\vfill
\hfill\parbox{5cm} {
           Выполнил:\\
           студент группы ИУ9-62Б \hfill \\
           Головкин Дмитрий\hfill \medskip\\
           Проверила:\\
           Домрачева А.Б.\hfill
       }
\centerline{Москва, 2023}
\clearpage
\end{titlepage}

\textsc{\textbf{Цель:}} 

Анализ метода наискорейшего спуска поиска минимума функций многих переменных.

\textsc{\textbf{Постановка задачи:}} 

\textbf{Дано:}  Функция нескольких переменных $ f(x_{1}, x_{2}, ...,x_{n}) $ и некоторое начальное приближение $ X^{0} = (x_{1}^{0}, ..., x_{n}^{0}). $

\textbf{Найти:} Минимум функции нескольких переменных с заданной точностью.

\textbf{Тестовый пример:} 

В качестве тестового примера были предложены следующие входные данные: $$ f(X) = e^{x_{1}} + (x_{1} + x_{2})^{2}, \quad X^{0} = (1,1) .$$

\textbf{Описание методов:}

Пусть мы имеем некоторое приближение к минимуму $X^{k} = (x_{1}^{k},...,x_{n}^{k})$. Рассмотрим функцию одной переменной $$ \phi_{k}(t) = f(x_{1}^k - t\frac{\partial f}{\partial x_{1}}(X^{k}),...,x_{n}^k - t\frac{\partial f}{\partial x_{n}}(X^{k})) = f(X^{k} - tgradf(X^{k})), $$ где вектор $ gradf(X^{k}) = (\frac{\partial f}{\partial x_{1}}(X^{k}),...,\frac{\partial f}{\partial x_{n}}(X^{k}) ) $ - градиент  функции f в точке $ X^{k}$. 

Обозначим точку минимума функции $\phi_{k}(t)$ через $t^{*}$. Тогда имеем следующую форму $$ X^{k+1} = X^{k} - t^{*}gradf(X^{k}) .$$
Процесс поиска минимума продолжаем до тех пор, пока $||gradf(X^{k})|| = \max_{1 \leq i \leq n} |\frac{\partial f}{\partial x_{i}}(X^{k})|$ не станет меньше допустимой погрешности $\epsilon$.

В большинстве случаев точно искать минимум функции $\phi_{k}(t)$ не нужно и достаточно ограничиться лишь одним приближением. Тогда особенно простым будет вид итерации в двумерном случае $$ (x_{k+1}, y_{k+1}) = (x_{k} - t^{k}\frac{\partial f}{\partial x} , y_{k} - t^{k}\frac{\partial f}{\partial y}) ,$$ где $t^{k} = \frac{\phi_{k}'(0)}{\phi_{k}''(0)}, \quad \phi_{k}'(0) = -(\frac{\partial f}{\partial x})^{2} - (\frac{\partial f}{\partial y})^{2}, \quad \phi_{k}''(0) = \frac{\partial f^{2}}{\partial x^{2}}(\frac{\partial f}{\partial x})^{2} + 2\frac{\partial f^{2}}{\partial x \partial y}\frac{\partial f}{\partial x}\frac{\partial f}{\partial y} + \frac{\partial f^{2}}{\partial y^{2}}(\frac{\partial f}{\partial y})^{2}$, все производные беруться в точке $(x_{k}, y_{k})$.

\textsc{\textbf{Практическая реализация:}}
Листинг 1. Метод наискорейшего спуска поиска минимума функций двух переменных
\begin{lstlisting}[language=python]
#!python
# -*- coding: utf-8 -*-

import matplotlib
import numpy as np
from matplotlib import pyplot as plt
from matplotlib.colors import ListedColormap

plt.rcParams["figure.figsize"] = (10,10)
plt.figure(figsize=(20, 20))
random_seed = 42

def func(x):
    return np.exp(x[0]) + (x[0] + x[1])**2

np.random.seed(random_seed)
w_0 = np.asarray([1,1])
w = w_0.copy()
w_list = [w.copy()]
eps = 1e-3
k = 0
max_der = 1

while max_der > eps:
    k += 1
    der1_x = np.exp(w[0]) + 2*(w[0] + w[1])
    der2_xx = np.exp(w[0]) + 2
    der1_y = 2*(w[0] + w[1])
    der2_yy = 2
    der2_xy = 2
    max_der = max(der1_x, der1_y)
    phi1_r = -(der1_x)**2 - (der1_y)**2
    phi2_r = der2_xx*(der1_x)**2 + 2*der2_xy*der1_x*der1_y + der2_yy*(der1_y)**2
    lr = -phi1_r / phi2_r
    #print(der1_y.astype(np.float64), der1_x)
    w = w - lr * np.asarray([der1_x.astype(np.float64), der1_y.astype(np.float64)])
    w_list.append(w.copy())
    
print(k, 'Num steps')
w_list = np.array(w_list)
w

def plot_convergence_2d(func, steps, ax, xlim, ylim, cmap="viridis", title=""):

    ax.set_title(title, fontsize=20, fontweight="bold")
    xrange = np.linspace(*xlim, 100)
    yrange = np.linspace(*ylim, 100)
    grid = np.meshgrid(xrange, yrange)
    X, Y = grid
    fvalues = np.array([func(x) for x in
        np.dstack(grid).reshape(-1, 2)]).reshape((xrange.size, yrange.size))
    ax.pcolormesh(xrange, yrange, fvalues, cmap=cmap, alpha=0.8)
    CS = ax.contour(xrange, yrange, fvalues)
    ax.clabel(CS, CS.levels, inline=True)
    arrow_kwargs = dict(linestyle="--", color="black", alpha=0.8)
    for i, _ in enumerate(steps):
        if i + 1 < len(steps):
            ax.arrow(
                *steps[i],
                *(steps[i+1] - steps[i]),
                **arrow_kwargs
            )
    n = len(steps)
    color_list = [(i / n, 0, 0, 1 - i / n) for i in range(n)]
    ax.scatter(steps[:, 0], steps[:, 1], c=color_list, zorder=10)
    ax.scatter(steps[-1, 0], steps[-1, 1], 
               color="red", label=f"estimate = {np.round(steps[-1], 2)}")
    ax.set_xlim(xlim)
    ax.set_ylim(ylim)
    ax.set_ylabel("$y$")
    ax.set_xlabel("$x$")
    ax.legend(fontsize=16)

fig, axes = plt.subplots(figsize=(10, 10), squeeze=False)
fig.suptitle("Steepest Descent 2D", fontsize=25, fontweight="bold")
plot_convergence_2d(func, w_list, axes[np.unravel_index(0, shape=axes.shape)], (-6, 1.1), (-1.1, 6))

\end{lstlisting}

\textbf{Результаты:}

В результате работы программы (Листинг 1), был вычислен приближенно с точность $\epsilon = 0.001$ минимум заданной функции. Приближенным минимумом является точка [-5.68862217,  5.68983688]. Алгоритм сошелся за достаточно большое число шагов - 587. Это связанно с тем, что функция имеет область с очень слабо изменяющимся градиентом, и глобального минимума не существует, так как из вида функции ясно, что минимум будет в точке $[-\infty, \infty]$.
Таким образом, если увеличивать точность, вычисленная алгоритмом точка будет приближаться к точке $[-\infty, \infty]$.

\textbf{Выводы:}

В ходе выполнения лабораторной работы был рассмотрен метод наискорейшего спуска для поиска минимума функции двух переменных. Для этого метода была написана реализация на языке программирования Python. Анализируя результаты полученной программы, можно заметить, что работа метода сильно зависит от начальных условий, а также от вида функции, которую необходимо минимизировать. Так, если у функциии достаточно маленький градиент, то может потребоваться заметно большее число операций для достижения необходимой точность, чем если бы у функции был четко выраженный минимум. Также немаловажен и выбор начальной точки, так как при неудачном выборе алгоритм моджет сойтись к локальному, а не глобальному минимуму.

\end{document}
